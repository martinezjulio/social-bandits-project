# Social Learning with Multi-Armed Bandits

Welcome to the Social Learning with Multi-Armed Bandits project!  
This project explores how humans learn through experimentation and observation.

## Repos
Here are the repositories involved in this project:
- [Experiment Code](https://github.com/martinezjulio/AsteroidMiningExperiment_CogSci2024): Code for running the multi-armed bandit experiment.
- [Analysis Code](https://github.com/martinezjulio/social-bandits-analyis): Data analysis, figures and results.
- [Modeling Code](https://github.com/martinezjulio/social-bandits-modeling): Modeling humans on social multiarmed bandits experiment.

## Project Board
[GitHub Project Board](https://github.com/users/martinezjulio/projects/3).

## Contact
Julio Martinez

juliomz@stanford.edu
